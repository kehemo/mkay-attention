#include <cuda_bf16.h>
#include <algorithm>
#include <chrono>
#include <cmath>
#include <cstdint>
#include <cstdio>
#include <cuda_runtime.h>
#include <fstream>
#include <functional>
#include <iostream>
#include <random>
#include <string>
#include <vector>
#pragma once

void cuda_check(cudaError_t code, const char *file, int line)
{
    if (code != cudaSuccess)
    {
        std::cerr << "CUDA error at " << file << ":" << line << ": "
                  << cudaGetErrorString(code) << std::endl;
        exit(1);
    }
}

#define CUDA_CHECK(x)                        \
    do                                       \
    {                                        \
        cuda_check((x), __FILE__, __LINE__); \
    } while (0)
typedef __nv_bfloat16 num;

__global__ void add_one_kernel(float *data, int size)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size)
    {
        data[idx] += 1.0;
    }
}

////////////////////////////////////////////////////////////////////////////////
///  YOU DO NOT NEED TO MODIFY THE CODE ABOVE HERE (unless you want to).     ///
////////////////////////////////////////////////////////////////////////////////

/// <--- your code here --->

constexpr int tile_dim = 32;
constexpr int num_threads_axis = 32;

__global__ void compute_attn_scores(
    const num *q, const num *k, const num *v,
    num *scores,
    int batch_size, int nheads, int seqlen, int head_dim,
    int64_t batch_stride, int64_t token_stride, int64_t head_stride, int64_t dim_stride)
{
    /*
    INPUTS:
    q,k,v === (batch_size, seqlen, nheads, head_dim)
    OUTPUTS:
    scores === (batch_size, nheads, seqlen, seqlen)
    NOTES:
    Computes q @ k.T along the seqlen dimension
    */

    uint32_t block_id = blockIdx.x;
    uint32_t batch_id = block_id / nheads;
    uint32_t head_id = block_id % nheads;

    uint32_t tile_i = blockIdx.y;
    uint32_t tile_j = blockIdx.z;
    uint32_t thread_i = threadIdx.x;
    uint32_t thread_j = threadIdx.y;
    num softmax_score = hrsqrt(__int2bfloat16_rd(head_dim));

    for (int row = thread_i; row < tile_dim; row += num_threads_axis)
    {
        for (int col = thread_j; col < tile_dim; col += num_threads_axis)
        {
            // compute "score[i][j] = sum_k q[i][d] * k[j][d]"
            num sum = __float2bfloat16(0.0);
            int i = tile_i * tile_dim + row;
            int j = tile_j * tile_dim + col;

            for (int d = 0; d < head_dim; d++)
            {

                uint32_t q_idx = batch_id * batch_stride + i * token_stride + head_id * head_stride + d * dim_stride;
                uint32_t k_idx = batch_id * batch_stride + j * token_stride + head_id * head_stride + d * dim_stride;

                num q_val = q[q_idx];
                num k_val = k[k_idx];

                sum += q_val * k_val;
            }

            uint32_t batch_stride_out = nheads * seqlen * seqlen;
            uint32_t head_stride_out = seqlen * seqlen;
            uint32_t token_stride_out = seqlen;
            uint32_t o_idx = batch_id * batch_stride_out + head_id * head_stride_out + i * token_stride_out + j;
            scores[o_idx] = sum * softmax_score;
        }
    }
}

__global__ void compute_attn_softmax(
    const num *S,
    num *P,
    int batch_size, int nheads, int seqlen, int head_dim)
{
    /*
    INPUTS:
    S === (batch_size, nheads, seqlen, seqlen)
        - attention scores (not softmaxed)
    OUTPUTS:
    P === (batch_size, nheads, seqlen, seqlen)
        - attention scores (softmaxed)
    */

    uint32_t batch_stride_S = nheads * seqlen * seqlen;
    uint32_t head_stride_S = seqlen * seqlen;
    uint32_t token_stride_S = seqlen;

    uint32_t batch_id = blockIdx.x;
    uint32_t head_id = blockIdx.y;
    uint32_t thread_id = threadIdx.x;
    uint32_t num_threads = blockDim.x;

    for (uint32_t query_id = thread_id; query_id < seqlen; query_id += num_threads)
    {
        // UHHH, we need a -inf for BF16, but i dont want to use -INFINITY in case of overflow or something
        num max_el = __float2bfloat16(-100.0);
        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            max_el = __hmax(max_el, S[s_idx]);
        }

        num sum = __float2bfloat16(0.0);
        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            P[s_idx] = hexp(S[s_idx] - max_el);
            sum += P[s_idx];
        }

        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            P[s_idx] /= sum;
        }
    }
}

constexpr uint32_t n_threads_seqlen_k3 = 32;
constexpr uint32_t n_threads_head_dim_k3 = 4;
constexpr uint32_t seqlen_tile_k3 = n_threads_seqlen_k3;
constexpr uint32_t head_dim_tile_k3 = n_threads_head_dim_k3 * 4;
__global__ void compute_attn_output(
    const num *P, const num *V,
    num *O,
    int batch_size, int nheads, int seqlen, int head_dim,
    int64_t batch_stride_qkv, int64_t token_stride_qkv, int64_t head_stride_qkv, int64_t dim_stride_qkv)
{
    /*
    INPUTS:
    P === (batch_size, nheads, seqlen, seqlen)
        - attention scores (softmaxed)
    V === (batch_size, seqlen, nheads, head_dim)
        - values
    OUTPUTS:
    O === (batch_size, seqlen, nheads, head_dim)
        - attention output
    */

    uint32_t block_id = blockIdx.x;
    uint32_t batch_id = block_id / nheads;
    uint32_t head_id = block_id % nheads;

    uint32_t tile_seqlen = blockIdx.y;
    uint32_t tile_head_dim = blockIdx.z;
    uint32_t thread_seqlen = threadIdx.x;
    uint32_t thread_head_dim = threadIdx.y;

    for (int row = thread_seqlen; row < seqlen_tile_k3; row += n_threads_seqlen_k3)
    {
        for (int col = thread_head_dim; col < head_dim_tile_k3; col += n_threads_head_dim_k3)
        {
            num sum = __float2bfloat16(0.0);
            int query_id = tile_seqlen * seqlen_tile_k3 + row;
            int head_dim_id = tile_head_dim * head_dim_tile_k3 + col;

            if (head_dim_id >= head_dim)
            {
                break;
            }

            uint32_t batch_stride_P = nheads * seqlen * seqlen;
            uint32_t head_stride_P = seqlen * seqlen;
            uint32_t token_stride_P = seqlen;

            for (int key_id = 0; key_id < seqlen; key_id++)
            {
                uint32_t p_idx = batch_id * batch_stride_P + head_id * head_stride_P + query_id * token_stride_P + key_id;
                uint32_t v_idx = batch_id * batch_stride_qkv + key_id * token_stride_qkv + head_id * head_stride_qkv + head_dim_id * dim_stride_qkv;
                sum += P[p_idx] * V[v_idx];
            }

            uint32_t batch_stride_O = seqlen * nheads * head_dim;
            uint32_t query_stride_O = nheads * head_dim;
            uint32_t head_stride_O = head_dim;
            uint32_t o_idx = batch_id * batch_stride_O + query_id * query_stride_O + head_id * head_stride_O + head_dim_id;
            O[o_idx] = sum;
        }
    }
}

struct attention_params
{
    int batch_size;
    int nheads;
    int seqlen;
    int head_dim;
    int64_t batch_stride;
    int64_t token_stride;
    int64_t head_stride;
    int64_t dim_stride;
    float softmax_scale;
};

constexpr int shmem_max_size = 100000;
constexpr int tile_size = shmem_max_size / sizeof(num) / 4;

struct shmem_t
{
    num K_tile[tile_size];
    num V_tile[tile_size];
    num Q_tile[tile_size];
    num S_tile[tile_size];
};

__host__ __device__ int ceil_div(int a, int b)
{
    return (a + b - 1) / b;
}

__global__ void fill(num *buffer, num val, int buffer_len)
{
    int thread_x = threadIdx.x + blockIdx.x * blockDim.x;
    if (thread_x < buffer_len)
    {
        buffer[thread_x] = val;
    }
}

void launch_fill(num *buffer, num val, int buffer_len)
{
    constexpr int threads = 128;
    fill<<<ceil_div(buffer_len, threads), threads>>>(buffer, val, buffer_len);
}

__global__ void flash_attention(
    const num *q, const num *k, const num *v, num *o, num *l, num *m, int B_r, int B_c, attention_params params)
{
    int batch_idx = blockIdx.x;
    int head_idx = blockIdx.y;
    int b_r_idx = threadIdx.x;

    int qkvo_offset = batch_idx * params.batch_stride + head_idx * params.head_stride;
    const num *cur_q = &q[qkvo_offset];
    const num *cur_k = &k[qkvo_offset];
    const num *cur_v = &v[qkvo_offset];
    num *cur_o = &o[qkvo_offset];

    int lm_offset = (batch_idx * params.nheads + head_idx) * params.seqlen;
    num *cur_l = &l[lm_offset];
    num *cur_m = &m[lm_offset];

    extern __shared__ shmem_t shmem[];
    int T_r = ceil_div(params.seqlen, B_r);
    int T_c = ceil_div(params.seqlen, B_c);
    for (int j = 0; j < T_c; j++)
    {
        int b_c_limit = min(B_c, params.seqlen - j * B_c);
        num kv_tile_offset = j * B_c * params.token_stride;
        const num *cur_k_tile = &cur_k[kv_tile_offset];
        const num *cur_v_tile = &cur_v[kv_tile_offset];
        for (int block_idx = b_r_idx; block_idx < b_c_limit * params.head_dim; block_idx += B_r)
        {
            int b_c_idx = block_idx / params.head_dim;
            int d_idx = block_idx % params.head_dim;
            int kv_idx = b_c_idx * params.token_stride + d_idx * params.dim_stride;
            shmem->K_tile[b_c_idx * params.head_dim + d_idx] = cur_k_tile[kv_idx];
            shmem->V_tile[b_c_idx * params.head_dim + d_idx] = cur_v_tile[kv_idx];
        }
        __syncthreads();
        for (int i = 0; i < T_r; i++)
        {
            if (i * B_r + b_r_idx >= params.seqlen)
                continue;
            int qo_tile_offset = i * B_r * params.token_stride;
            const num *cur_q_tile = &cur_q[qo_tile_offset];
            num *cur_o_tile = &cur_o[qo_tile_offset];
            int lm_tile_offset = i * B_r;
            num *cur_l_tile = &cur_l[lm_tile_offset];
            num *cur_m_tile = &cur_m[lm_tile_offset];
            for (int d_idx = 0; d_idx < params.head_dim; d_idx++)
            {
                int q_idx = b_r_idx * params.token_stride + d_idx * params.dim_stride;
                shmem->Q_tile[b_r_idx * params.head_dim + d_idx] = cur_q_tile[q_idx];
            }
            num row_m = -__float2bfloat16(INFINITY);
            for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
            {
                num sum = 0;
                for (int d_idx = 0; d_idx < params.head_dim; d_idx++)
                {
                    sum += shmem->Q_tile[b_r_idx * params.head_dim + d_idx] * shmem->K_tile[b_c_idx * params.head_dim + d_idx];
                }
                sum *= __float2bfloat16(params.softmax_scale);
                shmem->S_tile[b_c_idx * B_r + b_r_idx] = sum;
                row_m = __hmax(sum, row_m);
            }
            num row_l = 0;
            for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
            {
                row_l += hexp(shmem->S_tile[b_c_idx * B_r + b_r_idx] - row_m);
            }
            num old_m = cur_m_tile[b_r_idx];
            num old_l = cur_l_tile[b_r_idx];
            num new_m = __hmax(row_m, old_m);
            num new_l = hexp(old_m - new_m) * old_l + hexp(row_m - new_m) * row_l;
            for (int d_idx = 0; d_idx < params.head_dim; d_idx++)
            {
                num *o_cell = &cur_o_tile[b_r_idx * params.token_stride + d_idx * params.dim_stride];
                num pv_sum = 0;
                for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
                {
                    pv_sum += hexp(shmem->S_tile[b_c_idx * B_r + b_r_idx] - row_m) * shmem->V_tile[b_c_idx * params.head_dim + d_idx];
                }
                *o_cell = (old_l * hexp(old_m - new_m) * (*o_cell) + hexp(row_m - new_m) * pv_sum) / new_l;
            }
            cur_l_tile[b_r_idx] = new_l;
            cur_m_tile[b_r_idx] = new_m;
        }
        __syncthreads();
    }
}

void launch_flash_attention(
    const num *q, const num *k, const num *v, num *o, num *l, num *m, attention_params params)
{

    launch_fill(o, __float2bfloat16(0.0f), params.batch_size * params.nheads * params.head_dim * params.seqlen);
    launch_fill(l, __float2bfloat16(0.0f), params.batch_size * params.nheads * params.seqlen);
    launch_fill(m, __float2bfloat16(-INFINITY), params.batch_size * params.nheads * params.seqlen);
    int B_r = tile_size / params.head_dim;
    int B_c = min(B_r, params.head_dim);
    dim3 blocks = dim3(params.batch_size, params.nheads);
    CUDA_CHECK(cudaFuncSetAttribute(
        flash_attention,
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        sizeof(shmem_t)));
    flash_attention<<<blocks, B_r, sizeof(shmem_t)>>>(q, k, v, o, l, m, B_r, B_c, params);
}