#include <cuda_bf16.h>
#include <algorithm>
#include <chrono>
#include <cmath>
#include <cstdint>
#include <cstdio>
#include <cuda_runtime.h>
#include <fstream>
#include <functional>
#include <iostream>
#include <random>
#include <string>
#include <vector>
#include <cassert>
#pragma once

void cuda_check(cudaError_t code, const char *file, int line)
{
    if (code != cudaSuccess)
    {
        std::cerr << "CUDA error at " << file << ":" << line << ": "
                  << cudaGetErrorString(code) << std::endl;
        exit(1);
    }
}

#define CUDA_CHECK(x)                        \
    do                                       \
    {                                        \
        cuda_check((x), __FILE__, __LINE__); \
    } while (0)
typedef __nv_bfloat16 num;

__global__ void add_one_kernel(float *data, int size)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size)
    {
        data[idx] += 1.0;
    }
}

////////////////////////////////////////////////////////////////////////////////
///  YOU DO NOT NEED TO MODIFY THE CODE ABOVE HERE (unless you want to).     ///
////////////////////////////////////////////////////////////////////////////////

/// <--- your code here --->

constexpr int tile_dim = 32;
constexpr int num_threads_axis = 32;

__global__ void compute_attn_scores(
    const num *q, const num *k, const num *v,
    num *scores,
    int batch_size, int nheads, int seqlen, int head_dim,
    int64_t batch_stride, int64_t token_stride, int64_t head_stride, int64_t dim_stride)
{
    /*
    INPUTS:
    q,k,v === (batch_size, seqlen, nheads, head_dim)
    OUTPUTS:
    scores === (batch_size, nheads, seqlen, seqlen)
    NOTES:
    Computes q @ k.T along the seqlen dimension
    */

    uint32_t block_id = blockIdx.x;
    uint32_t batch_id = block_id / nheads;
    uint32_t head_id = block_id % nheads;

    uint32_t tile_i = blockIdx.y;
    uint32_t tile_j = blockIdx.z;
    uint32_t thread_i = threadIdx.x;
    uint32_t thread_j = threadIdx.y;
    num softmax_score = hrsqrt(__int2bfloat16_rd(head_dim));

    for (int row = thread_i; row < tile_dim; row += num_threads_axis)
    {
        for (int col = thread_j; col < tile_dim; col += num_threads_axis)
        {
            // compute "score[i][j] = sum_k q[i][d] * k[j][d]"
            num sum = __float2bfloat16(0.0);
            int i = tile_i * tile_dim + row;
            int j = tile_j * tile_dim + col;

            for (int d = 0; d < head_dim; d++)
            {

                uint32_t q_idx = batch_id * batch_stride + i * token_stride + head_id * head_stride + d * dim_stride;
                uint32_t k_idx = batch_id * batch_stride + j * token_stride + head_id * head_stride + d * dim_stride;

                num q_val = q[q_idx];
                num k_val = k[k_idx];

                sum += q_val * k_val;
            }

            uint32_t batch_stride_out = nheads * seqlen * seqlen;
            uint32_t head_stride_out = seqlen * seqlen;
            uint32_t token_stride_out = seqlen;
            uint32_t o_idx = batch_id * batch_stride_out + head_id * head_stride_out + i * token_stride_out + j;
            scores[o_idx] = sum * softmax_score;
        }
    }
}

__global__ void compute_attn_softmax(
    const num *S,
    num *P,
    int batch_size, int nheads, int seqlen, int head_dim)
{
    /*
    INPUTS:
    S === (batch_size, nheads, seqlen, seqlen)
        - attention scores (not softmaxed)
    OUTPUTS:
    P === (batch_size, nheads, seqlen, seqlen)
        - attention scores (softmaxed)
    */

    uint32_t batch_stride_S = nheads * seqlen * seqlen;
    uint32_t head_stride_S = seqlen * seqlen;
    uint32_t token_stride_S = seqlen;

    uint32_t batch_id = blockIdx.x;
    uint32_t head_id = blockIdx.y;
    uint32_t thread_id = threadIdx.x;
    uint32_t num_threads = blockDim.x;

    for (uint32_t query_id = thread_id; query_id < seqlen; query_id += num_threads)
    {
        // UHHH, we need a -inf for BF16, but i dont want to use -INFINITY in case of overflow or something
        num max_el = __float2bfloat16(-100.0);
        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            max_el = __hmax(max_el, S[s_idx]);
        }

        num sum = __float2bfloat16(0.0);
        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            P[s_idx] = hexp(S[s_idx] - max_el);
            sum += P[s_idx];
        }

        for (uint32_t key_id = 0; key_id < seqlen; key_id++)
        {
            uint32_t s_idx = batch_id * batch_stride_S + head_id * head_stride_S + query_id * token_stride_S + key_id;
            P[s_idx] /= sum;
        }
    }
}

constexpr uint32_t n_threads_seqlen_k3 = 32;
constexpr uint32_t n_threads_head_dim_k3 = 4;
constexpr uint32_t seqlen_tile_k3 = n_threads_seqlen_k3;
constexpr uint32_t head_dim_tile_k3 = n_threads_head_dim_k3 * 4;
__global__ void compute_attn_output(
    const num *P, const num *V,
    num *O,
    int batch_size, int nheads, int seqlen, int head_dim,
    int64_t batch_stride_qkv, int64_t token_stride_qkv, int64_t head_stride_qkv, int64_t dim_stride_qkv)
{
    /*
    INPUTS:
    P === (batch_size, nheads, seqlen, seqlen)
        - attention scores (softmaxed)
    V === (batch_size, seqlen, nheads, head_dim)
        - values
    OUTPUTS:
    O === (batch_size, seqlen, nheads, head_dim)
        - attention output
    */

    uint32_t block_id = blockIdx.x;
    uint32_t batch_id = block_id / nheads;
    uint32_t head_id = block_id % nheads;

    uint32_t tile_seqlen = blockIdx.y;
    uint32_t tile_head_dim = blockIdx.z;
    uint32_t thread_seqlen = threadIdx.x;
    uint32_t thread_head_dim = threadIdx.y;

    for (int row = thread_seqlen; row < seqlen_tile_k3; row += n_threads_seqlen_k3)
    {
        for (int col = thread_head_dim; col < head_dim_tile_k3; col += n_threads_head_dim_k3)
        {
            num sum = __float2bfloat16(0.0);
            int query_id = tile_seqlen * seqlen_tile_k3 + row;
            int head_dim_id = tile_head_dim * head_dim_tile_k3 + col;

            if (head_dim_id >= head_dim)
            {
                break;
            }

            uint32_t batch_stride_P = nheads * seqlen * seqlen;
            uint32_t head_stride_P = seqlen * seqlen;
            uint32_t token_stride_P = seqlen;

            for (int key_id = 0; key_id < seqlen; key_id++)
            {
                uint32_t p_idx = batch_id * batch_stride_P + head_id * head_stride_P + query_id * token_stride_P + key_id;
                uint32_t v_idx = batch_id * batch_stride_qkv + key_id * token_stride_qkv + head_id * head_stride_qkv + head_dim_id * dim_stride_qkv;
                sum += P[p_idx] * V[v_idx];
            }

            uint32_t batch_stride_O = seqlen * nheads * head_dim;
            uint32_t query_stride_O = nheads * head_dim;
            uint32_t head_stride_O = head_dim;
            uint32_t o_idx = batch_id * batch_stride_O + query_id * query_stride_O + head_id * head_stride_O + head_dim_id;
            O[o_idx] = sum;
        }
    }
}

struct attention_params
{
    int batch_size;
    int nheads;
    int seqlen;
    int head_dim;
    int64_t batch_stride;
    int64_t token_stride;
    int64_t head_stride;
    int64_t dim_stride;
    float softmax_scale;
};

constexpr int shmem_max_size = 100000;

template <int B_r, int B_c_split_size, int d_split_size, int splits>
struct shmem_t
{
    num K_tile[B_c_split_size * d_split_size * splits * splits];
    num V_tile[B_c_split_size * d_split_size * splits * splits];
    num Q_tile[B_r * d_split_size * splits];
    num S_tile[B_r * B_c_split_size * splits];
};

__host__ __device__ int ceil_div(int a, int b)
{
    return (a + b - 1) / b;
}

constexpr int max_threads = 256;

template <int B_r, int B_c_split_size, int d_split_size, int splits>
__global__ void __launch_bounds__(128) flash_attention(
    const num *__restrict__ q, const num *__restrict__ k, const num *__restrict__ v, num *__restrict__ o, num *__restrict__ L, attention_params params)
{
    extern __shared__ shmem_t<B_r, B_c_split_size, d_split_size, splits> shmem[];
    int batch_idx = blockIdx.x;
    int head_idx = blockIdx.y;
    int i = blockIdx.z;
    int b_r_idx = threadIdx.x;
    int split_idx = threadIdx.y;
    int thread_idx = b_r_idx + split_idx * B_r;

    int qkvo_offset = batch_idx * params.batch_stride + head_idx * params.head_stride;
    const num *cur_q = &q[qkvo_offset];
    const num *cur_k = &k[qkvo_offset];
    const num *cur_v = &v[qkvo_offset];
    num *cur_o = &o[qkvo_offset];

    int L_offset = (batch_idx * params.nheads + head_idx) * params.seqlen;
    num *cur_L = &L[L_offset];

    int qo_tile_offset = i * B_r * params.token_stride;
    const num *tile_q = &cur_q[qo_tile_offset];
    num *tile_o = &cur_o[qo_tile_offset];
    int L_tile_offset = i * B_r;
    num *tile_L = &cur_L[L_tile_offset];

    float o_reg[d_split_size] = {0};
    float l = 0;
    num m = __float2bfloat16(-INFINITY);

    bool b_r_inbounds = (b_r_idx + i * B_r < params.seqlen);
    int d_split_start = split_idx * d_split_size;
    int d_split_end = min((split_idx + 1) * d_split_size, params.head_dim);
    int b_c_split_start = split_idx * B_c_split_size;
    int b_c_split_end = min((split_idx + 1) * B_c_split_size, params.seqlen);

    for (int d_idx = d_split_start; d_idx < d_split_end; d_idx++)
    {
        int q_idx = b_r_idx * params.token_stride + d_idx * params.dim_stride;
        if (b_r_inbounds)
        {
            shmem->Q_tile[b_r_idx + d_idx * B_r] = tile_q[q_idx];
        }
    }

    constexpr int B_c = B_c_split_size * splits;
    int T_c = ceil_div(params.seqlen, B_c);
    for (int j = 0; j < T_c; j++)
    {
        int b_c_limit = min(B_c, params.seqlen - j * B_c);
        int kv_tile_offset = j * B_c * params.token_stride;
        const num *tile_k = &cur_k[kv_tile_offset];
        const num *tile_v = &cur_v[kv_tile_offset];
        for (int block_idx = thread_idx; block_idx < b_c_limit * params.head_dim; block_idx += B_r * splits)
        {
            int d_idx = block_idx / B_c;
            int b_c_idx = block_idx % B_c;
            int kv_idx = b_c_idx * params.token_stride + d_idx * params.dim_stride;
            shmem->K_tile[b_c_idx + d_idx * B_c] = tile_k[kv_idx];
            shmem->V_tile[b_c_idx + d_idx * B_c] = tile_v[kv_idx];
        }
        __syncthreads();
        for (int b_c_idx = b_c_split_start; b_c_idx < b_c_split_end; b_c_idx++)
        {
            float sum = 0.0f;
            for (int d_idx = 0; d_idx < params.head_dim; d_idx++)
            {
                sum += __bfloat162float(shmem->Q_tile[b_r_idx + d_idx * B_r]) * __bfloat162float(shmem->K_tile[b_c_idx + d_idx * B_c]);
            }
            sum *= params.softmax_scale;
            shmem->S_tile[b_r_idx + b_c_idx * B_r] = sum;
        }
        __syncthreads();
        num new_m = m;
        for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
        {
            new_m = __hmax(new_m, shmem->S_tile[b_r_idx + b_c_idx * B_r]);
        }
        __syncthreads();
        float exp_diff = expf(__bfloat162float(m - new_m));
        for (int b_c_idx = b_c_split_start; b_c_idx < b_c_split_end; b_c_idx++)
        {
            num p = hexp(shmem->S_tile[b_r_idx + b_c_idx * B_r] - __float2bfloat16(new_m));
            shmem->S_tile[b_r_idx + b_c_idx * B_r] = p;
        }
        __syncthreads();
        float new_l = exp_diff * l;
        for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
        {
            new_l += __bfloat162float(shmem->S_tile[b_r_idx + b_c_idx * B_r]);
        }
        for (int d_split_idx = 0; d_split_idx < d_split_size; d_split_idx++)
        {
            o_reg[d_split_idx] *= exp_diff;
        }
        for (int b_c_idx = 0; b_c_idx < b_c_limit; b_c_idx++)
        {
            for (int d_split_idx = 0; d_split_idx < d_split_size; d_split_idx++)
            {
                int d_idx = d_split_idx + d_split_start;
                o_reg[d_split_idx] += __bfloat162float(shmem->S_tile[b_r_idx + b_c_idx * B_r]) * __bfloat162float(shmem->V_tile[b_c_idx + d_idx * B_c]);
            }
        }
        m = new_m;
        l = new_l;
    }
    for (int d_split_idx = 0; d_split_idx < d_split_size; d_split_idx++)
    {
        int d_idx = d_split_start + d_split_idx;
        int o_idx = b_r_idx * params.token_stride + d_idx * params.dim_stride;
        if (d_idx < params.head_dim && b_r_inbounds)
        {
            tile_o[o_idx] = __float2bfloat16(o_reg[d_split_idx] / l);
        }
    }
    if (b_r_inbounds)
    {
        tile_L[b_r_idx] = m + __float2bfloat16(log(l));
    }
}

void launch_flash_attention(
    const num *q, const num *k, const num *v, num *o, num *L, attention_params params)
{
    constexpr int splits = 2;
    constexpr int B_r = 64;
    constexpr int B_c_split_size = 64;
    int T_r = ceil_div(params.seqlen, B_r);
    dim3 blocks = dim3(params.batch_size, params.nheads, T_r);
    dim3 threads = dim3(B_r, splits);
    constexpr int d_split_size = 64;
    assert(d_split_size * splits >= params.head_dim);
    typedef shmem_t<B_r, B_c_split_size, d_split_size, splits> shmem_t_instance;
    CUDA_CHECK(cudaFuncSetAttribute(
        flash_attention<B_r, B_c_split_size, d_split_size, splits>,
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        sizeof(shmem_t_instance)));
    flash_attention<B_r, B_c_split_size, d_split_size, splits>
        <<<blocks, threads, sizeof(shmem_t_instance)>>>(q, k, v, o, L, params);
}